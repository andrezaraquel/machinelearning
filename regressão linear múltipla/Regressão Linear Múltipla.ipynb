{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Múltipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regressão Múltipla com sklearn\n",
    "\n",
    "Neste documento, a ideia é criar um modelo de regressão linear múltipla. Esse modelo será ajustado aos dados de notas de alunos de computação da UFCG em algumas disciplinas do primeiro período. A última coluna é a variável alvo representando o CRA final depois de concluir o curso. As outras colunas são algumas disciplinas do primeiro período. O pressuposto aqui é que as notas em disciplinas no primeiro período ajudam a explicar o CRA final dos alunos de computação.\n",
    "\n",
    "Primeiramente, vou usar a biblioteca *sklearn* para criar o modelo. Depois de criado o modelo linear, a função *fit()* o ajusta aos dados (**X** contém todas as colunas de notas dos alunos e **Y** é o vetor com a coluna do cra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1.0075569152832031 ms intercept = [1.73771151], linear_coefficients = [[0.10304143 0.0464367  0.16409834 0.38117843 0.02027816]] error (R²) = 0.423803240951211\n"
     ]
    }
   ],
   "source": [
    "grades = np.genfromtxt(\"sample_students_grades.csv\", delimiter=\",\", skip_header=1)\n",
    "\n",
    "X = grades[:,[0,1,2,3,4]]\n",
    "Y = grades[:,5][:,np.newaxis]\n",
    "\n",
    "startTime = time.time()\n",
    "linear_reg = linear_model.LinearRegression() # this creates a linear regression object\n",
    "linear_reg.fit(X,Y) #this function fits a linear model\n",
    "\n",
    "endTime = time.time()\n",
    "#print(linear_reg.score(X,Y)) #R² error\n",
    "#print(linear_reg.coef_) # w1, w2, w3, ...\n",
    "#print(linear_reg.intercept_) # w0\n",
    "print(\"After {0} ms intercept = {1}, linear_coefficients = {2} error (R²) = {3}\".format(str(1000*(endTime-startTime)), linear_reg.intercept_, linear_reg.coef_, linear_reg.score(X,Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regressão Múltipla \"do zero\"\n",
    "\n",
    "Agora, farei um modelo e o ajustarei aos dados sem utilizar a biblioteca. Ao final, compararei os coeficientes do novo modelo com os coeficientes do modelo criado anteriormente. Isso será o teste que indicará se o novo algoritmo está funcionando corretamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Mean Squared Error\n",
    "\n",
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Mean Squared Error\n",
    "def compute_mse_vectorized(w,X,Y):\n",
    "    res = Y - np.dot(X, w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "attachments": {
    "gradienteDoRSS.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gradient\n",
    "\n",
    "A condição de parada do nosso algoritmo é baseada no gradiente do RSS, dado pela seguinte fórmula, onde H é a matriz de variáveis e seus valores, y o vetor de resultados e w é vetor dos parâmetros:![gradienteDoRSS.PNG](attachment:gradienteDoRSS.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    \n",
    "    res = Y - np.dot(X, w_current) # (y−Hw)\n",
    "   \n",
    "    gradients = np.multiply(-2, np.dot(X.T, res)) # -2H.T (y−Hw)\n",
    "    \n",
    "    rate = np.multiply(learningRate, gradients)  # α * -2H.T (y−Hw)  \n",
    "    \n",
    "    new_w = w_current - rate # w(t) − α * -2H.T (y−Hw)\n",
    "    \n",
    "    return [new_w,gradients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    gradients = np.array([np.inf])\n",
    "    i = 0\n",
    "    while (np.linalg.norm(gradients)>=epsilon):\n",
    "        w,gradients = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        \n",
    "        #print(np.linalg.norm(gradients))\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print(\"MSE in the iteration {0} is equals to {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "        i+= 1\n",
    "    print(\"It converged with {0} iterations.\".format(i))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main\n",
    "\n",
    "Como pode-se observar pela saída, o código converge com 333314 iterações quando os parâmetros são: **learning_rate = 0.00003** e **epsilon = 0.00001**. Os dois parâmetros foram sendo variados até que os coeficientes se aproximassem dos coeficientes encontrados pelo modelo criado com a biblioteca sklearn.\n",
    "\n",
    "Depois de aproximadamente 3385 ms, w0 = 1.73770337, w1 = 0.10304158, w2 = 0.04643707, w3 = 0.16409833, w4 = 0.38117884  e w5 = 0.02027826, com erro de 0.41133759. \n",
    "\n",
    "Como é possível observar, esses valores se aproximam dos valores retornados pelo modelo criado com a biblioteca sklearn, com a precisão de 4 casas decimais. Apenas o erro se aproxima com a precisão de somente 1 casa decimal.\n",
    "Relembrando, os valores do modelo do sklearn foram: w0 = 1.73771151, w1 = 0.10304143, w2 = 0.0464367, w3 = 0.16409834, w4 = 0.38117843 e w5 = 0.02027816, com erro de 0.423803240951211;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at w = [[0. 0. 0. 0. 0. 0.]], error = [[54.47995386]]\n",
      "Running...\n",
      "MSE in the iteration 0 is equals to [[15.39415211]]\n",
      "MSE in the iteration 10000 is equals to [[0.42109776]]\n",
      "MSE in the iteration 20000 is equals to [[0.41601668]]\n",
      "MSE in the iteration 30000 is equals to [[0.41358078]]\n",
      "MSE in the iteration 40000 is equals to [[0.41241299]]\n",
      "MSE in the iteration 50000 is equals to [[0.41185314]]\n",
      "MSE in the iteration 60000 is equals to [[0.41158475]]\n",
      "MSE in the iteration 70000 is equals to [[0.41145608]]\n",
      "MSE in the iteration 80000 is equals to [[0.41139439]]\n",
      "MSE in the iteration 90000 is equals to [[0.41136482]]\n",
      "MSE in the iteration 100000 is equals to [[0.41135064]]\n",
      "MSE in the iteration 110000 is equals to [[0.41134385]]\n",
      "MSE in the iteration 120000 is equals to [[0.41134059]]\n",
      "MSE in the iteration 130000 is equals to [[0.41133903]]\n",
      "MSE in the iteration 140000 is equals to [[0.41133828]]\n",
      "MSE in the iteration 150000 is equals to [[0.41133792]]\n",
      "MSE in the iteration 160000 is equals to [[0.41133775]]\n",
      "MSE in the iteration 170000 is equals to [[0.41133767]]\n",
      "MSE in the iteration 180000 is equals to [[0.41133763]]\n",
      "MSE in the iteration 190000 is equals to [[0.41133761]]\n",
      "MSE in the iteration 200000 is equals to [[0.4113376]]\n",
      "MSE in the iteration 210000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 220000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 230000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 240000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 250000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 260000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 270000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 280000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 290000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 300000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 310000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 320000 is equals to [[0.41133759]]\n",
      "MSE in the iteration 330000 is equals to [[0.41133759]]\n",
      "It converged with 333314 iterations.\n",
      "After 3385.5669498443604 ms w = [[1.73770337 0.10304158 0.04643707 0.16409833 0.38117884 0.02027826]], error = [[0.41133759]]\n"
     ]
    }
   ],
   "source": [
    "grades_incremented = np.c_[np.ones(len(grades)),grades]\n",
    "\n",
    "X = grades_incremented[:,[0,1,2,3,4,5]] # grades without cra\n",
    "Y = grades_incremented[:,6][:,np.newaxis] # cra\n",
    "init_w = np.zeros((6,1)) # vector of coefficients\n",
    "\n",
    "learning_rate = 0.00003\n",
    "epsilon = 0.00001\n",
    "\n",
    "print(\"Starting gradient descent at w = {0}, error = {1}\".format(init_w.T, compute_mse_vectorized(init_w, X,Y)))\n",
    "print(\"Running...\")\n",
    "startTime = time.time()\n",
    "w = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "endTime = time.time()\n",
    "print(\"After {0} ms w = {1}, error = {2}\".format(str(1000*(endTime-startTime)), w.T, compute_mse_vectorized(w,X,Y)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
