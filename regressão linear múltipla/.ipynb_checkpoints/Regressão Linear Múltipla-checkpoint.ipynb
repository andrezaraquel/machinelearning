{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Múltipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regressão Múltipla com sklearn\n",
    "\n",
    "Neste documento, a ideia é criar um modelo de regressão linear múltipla. Esse modelo será ajustado aos dados de notas de alunos de computação da UFCG em algumas disciplinas do primeiro período. A última coluna é a variável alvo representando o CRA final depois de concluir o curso. As outras colunas são algumas disciplinas do primeiro período. O pressuposto aqui é que as notas em disciplinas no primeiro período ajudam a explicar o CRA final dos alunos de computação.\n",
    "\n",
    "Primeiramente, vou usar a biblioteca *sklearn* para criar o modelo. Depois de criado o modelo linear, a função *fit()* o ajusta aos dados (**X** contém todas as colunas de notas dos alunos e **Y** é o vetor com a coluna do cra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 49.76296424865723 ms intercept = [1.73771151], linear_coefficients = [[0.10304143 0.0464367  0.16409834 0.38117843 0.02027816]] error (R²) = 0.423803240951211\n"
     ]
    }
   ],
   "source": [
    "grades = np.genfromtxt(\"sample_students_grades.csv\", delimiter=\",\", skip_header=1)\n",
    "\n",
    "X = grades[:,[0,1,2,3,4]]\n",
    "Y = grades[:,5][:,np.newaxis]\n",
    "\n",
    "startTime = time.time()\n",
    "linear_reg = linear_model.LinearRegression() # this creates a linear regression object\n",
    "linear_reg.fit(X,Y) #this function fits a linear model\n",
    "\n",
    "endTime = time.time()\n",
    "#print(linear_reg.score(X,Y)) #R² error\n",
    "#print(linear_reg.coef_) # w1, w2, w3, ...\n",
    "#print(linear_reg.intercept_) # w0\n",
    "print(\"After {0} ms intercept = {1}, linear_coefficients = {2} error (R²) = {3}\".format(str(1000*(endTime-startTime)), linear_reg.intercept_, linear_reg.coef_, linear_reg.score(X,Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regressão Múltipla \"do zero\"\n",
    "\n",
    "Agora, farei um modelo e o ajustarei aos dados sem utilizar a biblioteca. Ao final, compararei os coeficientes do novo modelo com os coeficientes do modelo criado anteriormente. Isso será o teste que indicará se o novo algoritmo está funcionando corretamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Mean Squared Error\n",
    "\n",
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Mean Squared Error\n",
    "def compute_mse_vectorized(w,X,Y):\n",
    "    res = Y - np.dot(X, w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    \n",
    "    res = Y - np.dot(X, w_current) # (y−Hw)\n",
    "   \n",
    "    gradients = np.dot(X.T, res) # H.T (y−Hw)\n",
    "\n",
    "    # α * -2HT (y−Hw): it didn't worked with this formula. \n",
    "    # So I replaced the (-2)  with the len(X) dividing\n",
    "    rate = np.multiply(learningRate/len(X), gradients)    \n",
    "    new_w = w_current + rate # w(t) − α * -2HT (y−Hw)\n",
    "    \n",
    "    return [new_w,gradients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    gradients = np.array([np.inf])\n",
    "    i = 0\n",
    "    while (np.linalg.norm(gradients)>=epsilon):\n",
    "        w,gradients = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        \n",
    "        #print(np.linalg.norm(gradients))\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"MSE in the iteration {0} is equals to {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "        i+= 1\n",
    "    print(\"It converged with {0} iterations.\".format(i))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main\n",
    "\n",
    "Como pode-se observar pela saída, o código converge com 212513 iterações quando os parâmetros são: **learning_rate = 0.0005** e **epsilon = 0.5**. Como pode ser visto no código acima (função *step_gradient_vectorized*), a taxa de aprendizado é dividida pelo tamanho de X. Não entendi muito bem o motivo, mas só convergiu dessa forma.\n",
    "\n",
    "Depois de 2047,2838878631592 ms, w0 = 0,92369587, w1 = 0,111762742, w2 = 0,08368884, w3 = 0,16224365, w4 = 0,42251334  e w5 = 0,03029537, com erro de 0,41597456. \n",
    "\n",
    "Como é possível observar, esses valores se aproximam dos valores retornados pelo modelo criado com a biblioteca sklearn que foram: w0 =1.73771151, w1 = 0.10304143, w2 = 0.0464367, w3 = 0.16409834 w4 = 0.38117843 e w5 = 0.02027816, com erro de 0.423803240951211;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at w = [[0. 0. 0. 0. 0. 0.]], error = [[54.47995386]]\n",
      "Running...\n",
      "MSE in the iteration 0 is equals to [[40.01097793]]\n",
      "MSE in the iteration 1000 is equals to [[0.46211023]]\n",
      "MSE in the iteration 2000 is equals to [[0.44714364]]\n",
      "MSE in the iteration 3000 is equals to [[0.43977622]]\n",
      "MSE in the iteration 4000 is equals to [[0.43584635]]\n",
      "MSE in the iteration 5000 is equals to [[0.43363992]]\n",
      "MSE in the iteration 6000 is equals to [[0.43235204]]\n",
      "MSE in the iteration 7000 is equals to [[0.43156975]]\n",
      "MSE in the iteration 8000 is equals to [[0.43107028]]\n",
      "MSE in the iteration 9000 is equals to [[0.43073036]]\n",
      "MSE in the iteration 10000 is equals to [[0.43048093]]\n",
      "MSE in the iteration 11000 is equals to [[0.43028308]]\n",
      "MSE in the iteration 12000 is equals to [[0.43011481]]\n",
      "MSE in the iteration 13000 is equals to [[0.42996369]]\n",
      "MSE in the iteration 14000 is equals to [[0.42982265]]\n",
      "MSE in the iteration 15000 is equals to [[0.42968771]]\n",
      "MSE in the iteration 16000 is equals to [[0.42955661]]\n",
      "MSE in the iteration 17000 is equals to [[0.42942807]]\n",
      "MSE in the iteration 18000 is equals to [[0.42930134]]\n",
      "MSE in the iteration 19000 is equals to [[0.42917602]]\n",
      "MSE in the iteration 20000 is equals to [[0.42905187]]\n",
      "MSE in the iteration 21000 is equals to [[0.42892875]]\n",
      "MSE in the iteration 22000 is equals to [[0.42880658]]\n",
      "MSE in the iteration 23000 is equals to [[0.42868531]]\n",
      "MSE in the iteration 24000 is equals to [[0.42856492]]\n",
      "MSE in the iteration 25000 is equals to [[0.42844537]]\n",
      "MSE in the iteration 26000 is equals to [[0.42832667]]\n",
      "MSE in the iteration 27000 is equals to [[0.42820879]]\n",
      "MSE in the iteration 28000 is equals to [[0.42809174]]\n",
      "MSE in the iteration 29000 is equals to [[0.4279755]]\n",
      "MSE in the iteration 30000 is equals to [[0.42786006]]\n",
      "MSE in the iteration 31000 is equals to [[0.42774543]]\n",
      "MSE in the iteration 32000 is equals to [[0.42763159]]\n",
      "MSE in the iteration 33000 is equals to [[0.42751855]]\n",
      "MSE in the iteration 34000 is equals to [[0.42740629]]\n",
      "MSE in the iteration 35000 is equals to [[0.4272948]]\n",
      "MSE in the iteration 36000 is equals to [[0.42718409]]\n",
      "MSE in the iteration 37000 is equals to [[0.42707415]]\n",
      "MSE in the iteration 38000 is equals to [[0.42696497]]\n",
      "MSE in the iteration 39000 is equals to [[0.42685655]]\n",
      "MSE in the iteration 40000 is equals to [[0.42674888]]\n",
      "MSE in the iteration 41000 is equals to [[0.42664196]]\n",
      "MSE in the iteration 42000 is equals to [[0.42653578]]\n",
      "MSE in the iteration 43000 is equals to [[0.42643034]]\n",
      "MSE in the iteration 44000 is equals to [[0.42632563]]\n",
      "MSE in the iteration 45000 is equals to [[0.42622164]]\n",
      "MSE in the iteration 46000 is equals to [[0.42611838]]\n",
      "MSE in the iteration 47000 is equals to [[0.42601583]]\n",
      "MSE in the iteration 48000 is equals to [[0.42591399]]\n",
      "MSE in the iteration 49000 is equals to [[0.42581287]]\n",
      "MSE in the iteration 50000 is equals to [[0.42571244]]\n",
      "MSE in the iteration 51000 is equals to [[0.42561271]]\n",
      "MSE in the iteration 52000 is equals to [[0.42551367]]\n",
      "MSE in the iteration 53000 is equals to [[0.42541532]]\n",
      "MSE in the iteration 54000 is equals to [[0.42531765]]\n",
      "MSE in the iteration 55000 is equals to [[0.42522065]]\n",
      "MSE in the iteration 56000 is equals to [[0.42512433]]\n",
      "MSE in the iteration 57000 is equals to [[0.42502868]]\n",
      "MSE in the iteration 58000 is equals to [[0.4249337]]\n",
      "MSE in the iteration 59000 is equals to [[0.42483937]]\n",
      "MSE in the iteration 60000 is equals to [[0.42474569]]\n",
      "MSE in the iteration 61000 is equals to [[0.42465267]]\n",
      "MSE in the iteration 62000 is equals to [[0.42456029]]\n",
      "MSE in the iteration 63000 is equals to [[0.42446855]]\n",
      "MSE in the iteration 64000 is equals to [[0.42437745]]\n",
      "MSE in the iteration 65000 is equals to [[0.42428698]]\n",
      "MSE in the iteration 66000 is equals to [[0.42419714]]\n",
      "MSE in the iteration 67000 is equals to [[0.42410792]]\n",
      "MSE in the iteration 68000 is equals to [[0.42401933]]\n",
      "MSE in the iteration 69000 is equals to [[0.42393134]]\n",
      "MSE in the iteration 70000 is equals to [[0.42384397]]\n",
      "MSE in the iteration 71000 is equals to [[0.4237572]]\n",
      "MSE in the iteration 72000 is equals to [[0.42367103]]\n",
      "MSE in the iteration 73000 is equals to [[0.42358546]]\n",
      "MSE in the iteration 74000 is equals to [[0.42350049]]\n",
      "MSE in the iteration 75000 is equals to [[0.42341611]]\n",
      "MSE in the iteration 76000 is equals to [[0.42333231]]\n",
      "MSE in the iteration 77000 is equals to [[0.42324909]]\n",
      "MSE in the iteration 78000 is equals to [[0.42316645]]\n",
      "MSE in the iteration 79000 is equals to [[0.42308438]]\n",
      "MSE in the iteration 80000 is equals to [[0.42300288]]\n",
      "MSE in the iteration 81000 is equals to [[0.42292195]]\n",
      "MSE in the iteration 82000 is equals to [[0.42284158]]\n",
      "MSE in the iteration 83000 is equals to [[0.42276177]]\n",
      "MSE in the iteration 84000 is equals to [[0.42268251]]\n",
      "MSE in the iteration 85000 is equals to [[0.4226038]]\n",
      "MSE in the iteration 86000 is equals to [[0.42252563]]\n",
      "MSE in the iteration 87000 is equals to [[0.42244801]]\n",
      "MSE in the iteration 88000 is equals to [[0.42237093]]\n",
      "MSE in the iteration 89000 is equals to [[0.42229438]]\n",
      "MSE in the iteration 90000 is equals to [[0.42221836]]\n",
      "MSE in the iteration 91000 is equals to [[0.42214287]]\n",
      "MSE in the iteration 92000 is equals to [[0.42206791]]\n",
      "MSE in the iteration 93000 is equals to [[0.42199346]]\n",
      "MSE in the iteration 94000 is equals to [[0.42191953]]\n",
      "MSE in the iteration 95000 is equals to [[0.42184612]]\n",
      "MSE in the iteration 96000 is equals to [[0.42177321]]\n",
      "MSE in the iteration 97000 is equals to [[0.42170081]]\n",
      "MSE in the iteration 98000 is equals to [[0.42162891]]\n",
      "MSE in the iteration 99000 is equals to [[0.42155751]]\n",
      "MSE in the iteration 100000 is equals to [[0.4214866]]\n",
      "MSE in the iteration 101000 is equals to [[0.42141619]]\n",
      "MSE in the iteration 102000 is equals to [[0.42134627]]\n",
      "MSE in the iteration 103000 is equals to [[0.42127683]]\n",
      "MSE in the iteration 104000 is equals to [[0.42120787]]\n",
      "MSE in the iteration 105000 is equals to [[0.42113939]]\n",
      "MSE in the iteration 106000 is equals to [[0.42107139]]\n",
      "MSE in the iteration 107000 is equals to [[0.42100386]]\n",
      "MSE in the iteration 108000 is equals to [[0.42093679]]\n",
      "MSE in the iteration 109000 is equals to [[0.42087019]]\n",
      "MSE in the iteration 110000 is equals to [[0.42080406]]\n",
      "MSE in the iteration 111000 is equals to [[0.42073838]]\n",
      "MSE in the iteration 112000 is equals to [[0.42067316]]\n",
      "MSE in the iteration 113000 is equals to [[0.42060839]]\n",
      "MSE in the iteration 114000 is equals to [[0.42054407]]\n",
      "MSE in the iteration 115000 is equals to [[0.4204802]]\n",
      "MSE in the iteration 116000 is equals to [[0.42041677]]\n",
      "MSE in the iteration 117000 is equals to [[0.42035378]]\n",
      "MSE in the iteration 118000 is equals to [[0.42029122]]\n",
      "MSE in the iteration 119000 is equals to [[0.4202291]]\n",
      "MSE in the iteration 120000 is equals to [[0.42016742]]\n",
      "MSE in the iteration 121000 is equals to [[0.42010616]]\n",
      "MSE in the iteration 122000 is equals to [[0.42004532]]\n",
      "MSE in the iteration 123000 is equals to [[0.41998491]]\n",
      "MSE in the iteration 124000 is equals to [[0.41992491]]\n",
      "MSE in the iteration 125000 is equals to [[0.41986533]]\n",
      "MSE in the iteration 126000 is equals to [[0.41980617]]\n",
      "MSE in the iteration 127000 is equals to [[0.41974742]]\n",
      "MSE in the iteration 128000 is equals to [[0.41968907]]\n",
      "MSE in the iteration 129000 is equals to [[0.41963113]]\n",
      "MSE in the iteration 130000 is equals to [[0.41957359]]\n",
      "MSE in the iteration 131000 is equals to [[0.41951645]]\n",
      "MSE in the iteration 132000 is equals to [[0.4194597]]\n",
      "MSE in the iteration 133000 is equals to [[0.41940335]]\n",
      "MSE in the iteration 134000 is equals to [[0.41934739]]\n",
      "MSE in the iteration 135000 is equals to [[0.41929182]]\n",
      "MSE in the iteration 136000 is equals to [[0.41923664]]\n",
      "MSE in the iteration 137000 is equals to [[0.41918183]]\n",
      "MSE in the iteration 138000 is equals to [[0.41912741]]\n",
      "MSE in the iteration 139000 is equals to [[0.41907337]]\n",
      "MSE in the iteration 140000 is equals to [[0.4190197]]\n",
      "MSE in the iteration 141000 is equals to [[0.4189664]]\n",
      "MSE in the iteration 142000 is equals to [[0.41891347]]\n",
      "MSE in the iteration 143000 is equals to [[0.41886091]]\n",
      "MSE in the iteration 144000 is equals to [[0.41880872]]\n",
      "MSE in the iteration 145000 is equals to [[0.41875688]]\n",
      "MSE in the iteration 146000 is equals to [[0.41870541]]\n",
      "MSE in the iteration 147000 is equals to [[0.41865429]]\n",
      "MSE in the iteration 148000 is equals to [[0.41860353]]\n",
      "MSE in the iteration 149000 is equals to [[0.41855312]]\n",
      "MSE in the iteration 150000 is equals to [[0.41850306]]\n",
      "MSE in the iteration 151000 is equals to [[0.41845334]]\n",
      "MSE in the iteration 152000 is equals to [[0.41840398]]\n",
      "MSE in the iteration 153000 is equals to [[0.41835495]]\n",
      "MSE in the iteration 154000 is equals to [[0.41830626]]\n",
      "MSE in the iteration 155000 is equals to [[0.41825792]]\n",
      "MSE in the iteration 156000 is equals to [[0.4182099]]\n",
      "MSE in the iteration 157000 is equals to [[0.41816222]]\n",
      "MSE in the iteration 158000 is equals to [[0.41811488]]\n",
      "MSE in the iteration 159000 is equals to [[0.41806786]]\n",
      "MSE in the iteration 160000 is equals to [[0.41802116]]\n",
      "MSE in the iteration 161000 is equals to [[0.41797479]]\n",
      "MSE in the iteration 162000 is equals to [[0.41792874]]\n",
      "MSE in the iteration 163000 is equals to [[0.41788302]]\n",
      "MSE in the iteration 164000 is equals to [[0.4178376]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE in the iteration 165000 is equals to [[0.41779251]]\n",
      "MSE in the iteration 166000 is equals to [[0.41774772]]\n",
      "MSE in the iteration 167000 is equals to [[0.41770325]]\n",
      "MSE in the iteration 168000 is equals to [[0.41765909]]\n",
      "MSE in the iteration 169000 is equals to [[0.41761523]]\n",
      "MSE in the iteration 170000 is equals to [[0.41757168]]\n",
      "MSE in the iteration 171000 is equals to [[0.41752842]]\n",
      "MSE in the iteration 172000 is equals to [[0.41748547]]\n",
      "MSE in the iteration 173000 is equals to [[0.41744282]]\n",
      "MSE in the iteration 174000 is equals to [[0.41740046]]\n",
      "MSE in the iteration 175000 is equals to [[0.4173584]]\n",
      "MSE in the iteration 176000 is equals to [[0.41731663]]\n",
      "MSE in the iteration 177000 is equals to [[0.41727514]]\n",
      "MSE in the iteration 178000 is equals to [[0.41723395]]\n",
      "MSE in the iteration 179000 is equals to [[0.41719304]]\n",
      "MSE in the iteration 180000 is equals to [[0.41715242]]\n",
      "MSE in the iteration 181000 is equals to [[0.41711208]]\n",
      "MSE in the iteration 182000 is equals to [[0.41707201]]\n",
      "MSE in the iteration 183000 is equals to [[0.41703223]]\n",
      "MSE in the iteration 184000 is equals to [[0.41699272]]\n",
      "MSE in the iteration 185000 is equals to [[0.41695348]]\n",
      "MSE in the iteration 186000 is equals to [[0.41691452]]\n",
      "MSE in the iteration 187000 is equals to [[0.41687583]]\n",
      "MSE in the iteration 188000 is equals to [[0.41683741]]\n",
      "MSE in the iteration 189000 is equals to [[0.41679925]]\n",
      "MSE in the iteration 190000 is equals to [[0.41676136]]\n",
      "MSE in the iteration 191000 is equals to [[0.41672373]]\n",
      "MSE in the iteration 192000 is equals to [[0.41668636]]\n",
      "MSE in the iteration 193000 is equals to [[0.41664925]]\n",
      "MSE in the iteration 194000 is equals to [[0.4166124]]\n",
      "MSE in the iteration 195000 is equals to [[0.4165758]]\n",
      "MSE in the iteration 196000 is equals to [[0.41653946]]\n",
      "MSE in the iteration 197000 is equals to [[0.41650337]]\n",
      "MSE in the iteration 198000 is equals to [[0.41646753]]\n",
      "MSE in the iteration 199000 is equals to [[0.41643194]]\n",
      "MSE in the iteration 200000 is equals to [[0.41639659]]\n",
      "MSE in the iteration 201000 is equals to [[0.4163615]]\n",
      "MSE in the iteration 202000 is equals to [[0.41632664]]\n",
      "MSE in the iteration 203000 is equals to [[0.41629203]]\n",
      "MSE in the iteration 204000 is equals to [[0.41625765]]\n",
      "MSE in the iteration 205000 is equals to [[0.41622352]]\n",
      "MSE in the iteration 206000 is equals to [[0.41618962]]\n",
      "MSE in the iteration 207000 is equals to [[0.41615596]]\n",
      "MSE in the iteration 208000 is equals to [[0.41612253]]\n",
      "MSE in the iteration 209000 is equals to [[0.41608933]]\n",
      "MSE in the iteration 210000 is equals to [[0.41605636]]\n",
      "MSE in the iteration 211000 is equals to [[0.41602363]]\n",
      "MSE in the iteration 212000 is equals to [[0.41599111]]\n",
      "It converged with 212513 iterations.\n",
      "After 2080.7723999023438 ms w = [[0.92369587 0.11762742 0.08368884 0.16224365 0.42251334 0.03029537]], error = [[0.41597456]]\n"
     ]
    }
   ],
   "source": [
    "grades_incremented = np.c_[np.ones(len(grades)),grades]\n",
    "\n",
    "X = grades_incremented[:,[0,1,2,3,4,5]] # grades without cra\n",
    "Y = grades_incremented[:,6][:,np.newaxis] # cra\n",
    "init_w = np.zeros((6,1)) # vector of coefficients\n",
    "\n",
    "learning_rate = 0.0005\n",
    "epsilon = 0.5\n",
    "\n",
    "print(\"Starting gradient descent at w = {0}, error = {1}\".format(init_w.T, compute_mse_vectorized(init_w, X,Y)))\n",
    "print(\"Running...\")\n",
    "startTime = time.time()\n",
    "w = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "endTime = time.time()\n",
    "print(\"After {0} ms w = {1}, error = {2}\".format(str(1000*(endTime-startTime)), w.T, compute_mse_vectorized(w,X,Y)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
